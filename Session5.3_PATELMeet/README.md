# Advanced Python â€” Session 5.3

## Pandas Data Cleaning Pipeline

This project is part of the **Advanced Python course â€” Session 5 (Part 3)**.
It focuses on building a robust and reusable **data cleaning pipeline using pandas**, following real-world data engineering practices.

The objective is to safely ingest messy CSV data, normalize it, compute key performance indicators (KPIs), and export a clean dataset ready for analysis.

---

## Project Goals

* Load structured CSV data using pandas
* Handle malformed rows safely
* Normalize textual and numeric fields
* Convert dates with error tolerance
* Remove duplicates and invalid records
* Engineer new business features
* Compute summary KPIs
* Export a cleaned dataset
* Maintain a clean, modular project structure

---

## Project Structure

```
Session5.3_PATELMeet/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ src/
â”‚   â””â”€â”€ cleaning.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ clients_clean.csv
â”‚   â””â”€â”€ clients_dirty.csv
â””â”€â”€ out/
    â””â”€â”€ clients_cleaned.csv
```

---

## Key Pipeline Steps

### ğŸ§© Data Loading

* Reads CSV using pandas
* Skips malformed rows using defensive parsing
* Performs initial inspection (shape, columns, missing values)

---

### ğŸ§¼ Data Cleaning

Implemented in `cleaning.py`:

* Numeric coercion with error handling
* Date parsing with invalid-date protection
* Text normalization (city and segment)
* Duplicate removal by `client_id`
* Dropping rows with critical missing values

---

### âš™ï¸ Feature Engineering

The pipeline derives new business metrics:

* **margin** = income âˆ’ spend
* **spend_ratio** = spend / income

These features are commonly used in customer analytics workflows.

---

### ğŸ“Š KPI Reporting

The script prints:

* Final row count
* Mean income
* Mean spend
* Top cities
* Mean margin

---

### ğŸ’¾ Export

Cleaned dataset is saved to:

```
out/clients_cleaned.csv
```

---

## Setup Instructions

Create and activate the virtual environment:

```
python -m venv venv
source venv/Scripts/activate
```

Install dependencies:

```
pip install -r requirements.txt
```

---

## How to Run

From the project directory:

```
python main.py --input data/clients_dirty.csv
```

You may also test with the clean dataset.

---

## Technologies Used

* Python
* pandas
* argparse
* Defensive data engineering practices

---

## Author

PATEL Meet
Advanced Python Course â€” Session 5.3
